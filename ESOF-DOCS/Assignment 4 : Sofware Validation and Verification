[1] - Discuss Software Testability and Reviews: 
controllability, observability, isolateability, separation of concerns, understandability, heterogeneityheterogeneity.  

A validação da versão mais recente do produto é efetuada, pelos utilizadores que podem submeter o pedidos de alterações/correções e 
novas funcionalidades através da plataforma JIRA, ou seja a validação é sempre efectuadas pelos utilizadores quer sejam Clinicas, pacientes
ou investigadores;

Não encontramos documentos de testes efetuados ao software e os testes existentes não estão descritos/comentados, o que dificulta
bastante em termos de controlabilidade, em alguns casos dispendiosos e impraticáveis.

Em termos de "Observability" é fácil determinar se os testes passaram, através do output, com o resultado dos testes. Esses resultados
esperados por vezes também estão comentados.
Parece existir por parte dos programadores uma preocupação em separar os testes em função dos resultados esperados.

"Isolateability": Com os testes existentes no software, as componentes podem ser testadas de forma isolada, com por exemplo o teste
a connectividade DAO. Para além disso, o JUNIT tem a particularidade de cada componente de cada classe poder ser testado de forma individual.

"Understandability": Como já foi referido acima não existem documentação dos testes efetuados ao software, nem comentários suficientes,
para compreeder facilmente sem leitura e interpretação do código. Ou seja, todo o processo de compreensão dos testes efetuados é moroso.

"Heterogeneity": Como o software é desenvolvido em Java, e software é flexivel para que as alterações/requisitos dos utilizadores sejam
facilmente implementadas. Para além disso o software baseia num sistema distribuido o que permite que o software seja partilhado na internet
e corra em várias plataformas.

[2] - Report Test Statistics and analytics

Existem testes em "JUNIT" (framework para testes automaticos na linguagem Java):
      - Teste de importação de dados, com validação de dados;
      - Testes de conectividade a base de dados, teste de login's;
      - Teste a entrada de expressões;
      - Teste com vários formatos de datas;
      - Teste ao serviços disponibilizados pela aplicação;
      - Verificação dos níveis de acesso para visualização e edição, no caso dos CRF's;
      
Basicamente os testes existentes na aplicação são para verificações de conectividade a diferentes fontes de dados,
analise de expressões, e teste a importação de dados.
      
Em alguns casos são criadas classes especificas para testes que são subclasses da classe TestCase da framework JUNIT.

Os erros são reportados JIRA. Uma plataforma que permite explorar por "issues" pendentes ou requisições de novas funcionalidades.
Permite criar registo de novos erros e pedidos de funcionalidades. O "ciclo de vida", do estado é reportado também no "JIRA"

Depois de efetuarmos o teste ao software OpenClinica, no "codacy" formam registados os seguintes dados:
Compatiblilidade software: 100%
Segurança:                  99%           (1 registo)
Code Style:                 78%           (2771 registos)
Performance:                93%           (264 registos)
Unused Code:                71%           (1177 registos)

No entanto estes últimos testes traduzem-se especficamente em defeitos de codificação e não em desvios a especificação/requesitos.

[3] - Identify a new bug and/or correct a bug

No âmbito deste projecto tornou-se bastante difícil a identificação de novos bugs. Isto deve-se ao facto de que este projecto já se 
encontra em circulação e todos os bugs que possam afectar o seu desempenho de forma significativa são sistematicamente corrigidos 
pelos responsáveis pelo projecto.
Tal como foi referido na secção anterior, usando o programa codacy conseguimos visualizar os bugs presentes no código e embora estes 
existam em grande número são bastante negligenciáveis e facilmente corrigiveis visto que grande parte deles tratam-se de más 
praticas ao nível da programação (ver exemplo 1), de variáveis declaradas que já não estão a ser utilizadas (ver exemplo 2) ou de 
linhas de código que estão propícias a erros (ver exemplo 3)

Legendas dos exemplos:
Exemplo 1:
Ao dar nomes a funções deve se utilizar a nomenclatura camelCase e evitar o uso de underscores. 
Exemplo 2:
Neste caso a variavel crfIndex não esta a ser utilizada e deve ser removida.
Exemplo 3:
Deve se evitar o uso de imports que não estejam a ser utilizados de forma a não causar dependências desnecessárias.

Trabalho desenvolvido em grupo,  com partipação de todos os elementos do grupo.
